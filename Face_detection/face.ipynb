{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c03e93a-6338-426f-9ad7-46606edb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5f94f3-1994-43a9-b707-86778f2e49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if ret==False:\n",
    "        continue\n",
    "\n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    cv2.imshow(\"Gray Frame\",gray_frame)\n",
    "\n",
    "    key_presses=cv2.waitKey(1) & 0xFF\n",
    "    if key_presses==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29168a8-5b3b-4792-9efd-665bda809344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of person: Saloni\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#Read and show video stream,capture images\n",
    "#detect faces and show bounding box\n",
    "#Flatten the largest face image(gray scale image) and save in numpy array\n",
    "#Repeat the above  for multiple people to generate training data\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#Face Detection\n",
    "face_cascade=cv2.CascadeClassifier(\"D:/Data Science/openCV/FaceRecognition/haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path=\"D:/Data Science/openCV/FaceRecognition/\"\n",
    "file_name=input(\"Enter the name of person:\")\n",
    "\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "\n",
    "    if ret==False:\n",
    "        continue\n",
    "\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)  ##1.3 is scaling parameter and 5 is number of neighbours\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    # print(faces)\n",
    "\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h= face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)  ##x and y are the corrdinates and w and h are width and height\n",
    "        \n",
    "\n",
    "        #Extract (Crop out the required face) : Region of interest\n",
    "        offset=10\n",
    "        face_section= frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        skip +=1\n",
    "        if skip %10==0:\n",
    "             face_data.append(face_section)\n",
    "             print(len(face_data))\n",
    "             \n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    cv2.imshow(\"Face section\",face_section)\n",
    "    \n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed==ord('q'):\n",
    "            break\n",
    "\n",
    "#convert our face list array into numpy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data Save successfully\"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913a098-3932-4eff-9891-4dd6818387a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebebd29b-a965-4842-bdde-868094b20362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of person: Prabakaran\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "(19, 30000)\n",
      "Data Save successfullyD:/Data Science/openCV/FaceRecognition/Prabakaran.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#Face Detection\n",
    "face_cascade=cv2.CascadeClassifier(\"D:/Data Science/openCV/FaceRecognition/haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path=\"D:/Data Science/openCV/FaceRecognition/\"\n",
    "file_name=input(\"Enter the name of person:\")\n",
    "\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "\n",
    "    if ret==False:\n",
    "        continue\n",
    "\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)  ##1.3 is scaling parameter and 5 is number of neighbours\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    # print(faces)\n",
    "\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h= face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)  ##x and y are the corrdinates and w and h are width and height\n",
    "        \n",
    "\n",
    "        #Extract (Crop out the required face) : Region of interest\n",
    "        offset=10\n",
    "        face_section= frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        skip +=1\n",
    "        if skip %10==0:\n",
    "             face_data.append(face_section)\n",
    "             print(len(face_data))\n",
    "             \n",
    "        cv2.imshow(\"Face section\",face_section)  # Moved inside the loop\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    \n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed==ord('q'):\n",
    "            break\n",
    "\n",
    "#convert our face list array into numpy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data Save successfully\"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e676c-3815-46d1-b7b2-0f8af8af2d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2f0d9-aa7e-48d7-8343-8fc971125d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55112d2b-1481-4866-afd7-7bf5f248831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded arif.npy\n",
      "[[119 115 132 ...  34  33  29]\n",
      " [121 122 131 ...  35  33  29]\n",
      " [107 112 117 ...  38  40  33]\n",
      " ...\n",
      " [115 118 128 ...  32  35  26]\n",
      " [119 120 131 ...  31  33  27]\n",
      " [116 119 129 ...  29  32  24]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "(15, 30001)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m     face_section\u001b[38;5;241m=\u001b[39mframe[y\u001b[38;5;241m-\u001b[39moffset:y\u001b[38;5;241m+\u001b[39mh\u001b[38;5;241m+\u001b[39moffset,x\u001b[38;5;241m-\u001b[39moffset:x\u001b[38;5;241m+\u001b[39mw\u001b[38;5;241m+\u001b[39moffset]\n\u001b[0;32m     87\u001b[0m     face_section\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(face_section,(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m---> 89\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mface_section\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Display on the screen and rectangle around it\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     pred_name\u001b[38;5;241m=\u001b[39mnames[\u001b[38;5;28mint\u001b[39m(out)]\n",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m, in \u001b[0;36mknn\u001b[1;34m(train, test, k)\u001b[0m\n\u001b[0;32m     28\u001b[0m dk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msorted\u001b[39m(dist, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m0\u001b[39m])[:k]\n\u001b[0;32m     29\u001b[0m  \u001b[38;5;66;03m# Retrieve only the labels\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m labels\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdk\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Get frequencies of each label\u001b[39;00m\n\u001b[0;32m     33\u001b[0m output\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(labels,return_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# load the training data\n",
    "# x-values are stored in the numpy arrays\n",
    "# y-values we need to assign to each person\n",
    "# use KNN to find the prediction of face\n",
    "# map the predicted id to name of the user\n",
    "# Display the predictions on screen-bounding box and name\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "########## KNN CODE ##########\n",
    "def distance(v1,v2):\n",
    "    # Eucledian\n",
    "    return np.sqrt(((v1-v2) ** 2).sum())\n",
    "\n",
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix=train[i, :-1]\n",
    "        iy=train[i, :-1]\n",
    "        # Compute the distance from test point\n",
    "        d=distance(test,ix)\n",
    "        dist.append([d,iy])\n",
    "     # Sort based on distance and get top k\n",
    "    dk=sorted(dist, key=lambda x:x[0])[:k]\n",
    "     # Retrieve only the labels\n",
    "    labels=np.array(dk)[:, -1]\n",
    "\n",
    "    # Get frequencies of each label\n",
    "    output=np.unique(labels,return_count=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "###############################################\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#Face Detection\n",
    "face_cascade=cv2.CascadeClassifier(\"D:/Data Science/openCV/FaceRecognition/haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path=\"D:/Data Science/openCV/FaceRecognition/\"\n",
    "labels=[]\n",
    "class_id=0  #labels for the given file\n",
    "names={}  #mapping between id-name\n",
    "\n",
    "# Data preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        # Create mapping btw class_id and name\n",
    "        names[class_id]=fx[:-4]\n",
    "        print(\"loaded\",fx)\n",
    "        data_item =np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "\n",
    "    # Create labels for the class\n",
    "        target =class_id*np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset=np.concatenate(face_data,axis=0)\n",
    "face_labels=np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "\n",
    "print(face_dataset)\n",
    "print(face_labels)\n",
    "\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(trainset.shape)\n",
    "\n",
    "# Testing\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "\n",
    "    # Get the face ROI\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "\n",
    "        out=knn(trainset,face_section.flatten())\n",
    " \n",
    "    # Display on the screen and rectangle around it\n",
    "        pred_name=names[int(out)]\n",
    "        cv2.putText(frame,pred_name,(x,y-10),FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"faces\",frame)\n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c0200-9f64-45bf-bf44-11c0e2e4d5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fc1c40-2788-4079-a05d-6ce81c4bac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded Ahmed.npy\n",
      "loaded arif.npy\n",
      "loaded Mudassir.npy\n",
      "loaded Prabakaran.npy\n",
      "[[153 161 160 ...  10  15   7]\n",
      " [148 159 159 ...  22  26  13]\n",
      " [158 173 173 ...  21  24  21]\n",
      " ...\n",
      " [109  81  64 ...  22  24  19]\n",
      " [180 181 179 ...  20  21  18]\n",
      " [ 84  61  56 ...  21  23  18]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]]\n",
      "(98, 30001)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "########## KNN CODE ##########\n",
    "def distance(v1, v2):\n",
    "    # Euclidean distance\n",
    "    return np.sqrt(((v1 - v2) ** 2).sum())\n",
    "\n",
    "def knn(train, test, k=5):\n",
    "    dist = []\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix, iy = train[i, :-1], train[i, -1]\n",
    "        # Compute the distance from test point\n",
    "        d = distance(test, ix)\n",
    "        dist.append((d, iy))\n",
    "\n",
    "    # Sort based on distance and get top k\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = [label for _, label in dk]\n",
    "\n",
    "    # Get frequencies of each label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "###############################################\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = \"D:/Data Science/openCV/FaceRecognition/\"\n",
    "labels = []\n",
    "class_id = 0  # labels for the given file\n",
    "names = {}  # mapping between id-name\n",
    "\n",
    "# Data preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        # Create mapping between class_id and name\n",
    "        names[class_id] = fx[:-4]\n",
    "        print(\"loaded\", fx)\n",
    "        data_item = np.load(dataset_path + fx)\n",
    "        face_data.append(data_item)\n",
    "\n",
    "        # Create labels for the class\n",
    "        target = class_id * np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data, axis=0)\n",
    "face_labels = np.concatenate(labels, axis=0).reshape((-1, 1))\n",
    "\n",
    "print(face_dataset)\n",
    "print(face_labels)\n",
    "\n",
    "trainset = np.concatenate((face_dataset, face_labels), axis=1)\n",
    "print(trainset.shape)\n",
    "\n",
    "# Testing\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == False:\n",
    "        continue\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "\n",
    "    for face in faces:\n",
    "        x, y, w, h = face\n",
    "\n",
    "        # Get the face ROI\n",
    "        offset = 10\n",
    "        face_section = frame[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "        face_section = cv2.resize(face_section, (100, 100))\n",
    "\n",
    "        out = knn(trainset, face_section.flatten())\n",
    "\n",
    "        # Display on the screen and rectangle around it\n",
    "        pred_name = names[int(out)]\n",
    "        cv2.putText(frame, pred_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"faces\", frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92c797-b235-4c36-a38f-546e519904ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
